{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bb833f0",
   "metadata": {},
   "source": [
    "# Skin Cancer detection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f816ca",
   "metadata": {},
   "source": [
    "## downloading tensorflow for the project\n",
    "##### run the following command in a code sell to download tensorflow\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f58976f",
   "metadata": {},
   "source": [
    "```terminal\n",
    "!pip install tensorflow\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85cb997",
   "metadata": {},
   "source": [
    "### transfer learning is used to make this project \n",
    "####  <u>Transfer learning</u> :   Transfer Learning is basically when you train a model on a data and then used that trained model on a diffrent but similer data so that you don't have to train the entire model , which may take a lot of time and GPU power and for a good preformance will also required a large data set, which we know may not be peresent and making our own data set is tedious and expencive task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d915cd8b",
   "metadata": {},
   "source": [
    "##### we will be using VGG16 and VGG19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a6a5dc",
   "metadata": {},
   "source": [
    "#### you can donload the data set form [here](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98550732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the necessary libraries\n",
    "from keras.layers import Input, Lambda, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential \n",
    "import numpy as np\n",
    "import glob as glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "930225e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-sizing all the images ,as we are delaing with rgb images so it will have 3 dimentions\n",
    "IMAGE_SIZE = [244, 244]\n",
    "\n",
    "train_path = 'skin_cancer/train'\n",
    "valid_path = 'skin_cancer/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7777f703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using vgg16 model , and we will be using imagenet weights, as they were the one who win the competion and so ther weights \n",
    "# are of the trained modle so we won't have to train the whole model , this is transfer learnig \n",
    "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights= 'imagenet', include_top=False)\n",
    "\n",
    "# [3] is for the dimention of the rgb imgae\n",
    "\n",
    "# include_top = False means we don't want the exact model as we are going to use a diffrent data set so , we will train \n",
    "# the the last layer and the output layer for out dataset so that the model predicts for this particular data set\n",
    "# in the vgg16 starting layers of the cnn identify the basic pattrens that are persent in all the images like lines, edges etc, \n",
    "# so we don't need to change the staring layers for that we have keept them as same and removed the top part that we will be \n",
    "# training for out data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c51ad01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are loading a pretrained model so we don't want to change the weights that we have laoded in the avobe code cell \n",
    "for layer in vgg.layers:\n",
    "        layer.trainable = False    # so that we don't train the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8e4a9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "folders = glob(\"data_set/train/*\")\n",
    "\n",
    "# this will tell us which folders are present in Data_set/train , * repersents all , "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35770845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data_set/train\\\\NORMAL', 'Data_set/train\\\\PNEUMONIA']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb2cc85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(vgg.output)\n",
    "# here flatten is bsically reducing the dimentionality of the layers , making it in 1D\n",
    "# vgg.output is the output layer and we are flattening the output layre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "288c65d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = Dense(len(folders), activation= \"softmax\")(x)\n",
    "# x is our output layer and we are usign Dense function to five it no. of neurons that there are in the train file\n",
    "# for this case there are only two , pneumonia and not pneumonia \n",
    "# we are using activatin function softmax\n",
    "\n",
    "model = Model(inputs = vgg.input, outputs = prediction)\n",
    "# we are giving the model the inputs that are pretrained form vgg and outputs according to out data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3981027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 244, 244, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 244, 244, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 244, 244, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 122, 122, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 122, 122, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 122, 122, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 61, 61, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 61, 61, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 61, 61, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 61, 61, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 30, 30, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 30, 30, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 30, 30, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 30, 30, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 15, 15, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 15, 15, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 15, 15, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 15, 15, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 50178     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14764866 (56.32 MB)\n",
      "Trainable params: 50178 (196.01 KB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6875a1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will compile the model , i.e. giving it all the things it will need to train well and make good predictions \n",
    "model.compile(loss = 'categorical_crossentropy', \n",
    "             optimizer = \"adam\",\n",
    "             metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bf27a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using image generator to import the images form the data set\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2, \n",
    "                                  horizontal_flip=True)\n",
    "\n",
    "# here we are configuring the ImageDataGenerator with the parameters like rescale and all so that our model performs well\n",
    "# it is adviced that if all the data is in same range then its better for the model \n",
    "### the basic reason we are doing this is because we want to increase out tring data somehow so that our model doesn't overfit\n",
    "### this data augmentation is helping us with generarating more data for the training \n",
    "\n",
    "# rescale = 1./255 is rescaling the image's pixel value that ranges form 0 to 255 by deviding by 255 we can make it in range of \n",
    "# [0,1], this is a convention for better training \n",
    "\n",
    "# shear_range=0.2 shearing means keeping one part of the image fixed and move the other part in one direction keeping the \n",
    "# image stationary, this can introduce diversity into the training data\n",
    "\n",
    "# horizontal_flip is used to mirror image this helps in making the model invarient to horizontal flips\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d5340da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# training data\n",
    "# make sure to provide the same target size as initialized before \n",
    "training_set = train_datagen.flow_from_directory(\"data_set/train\",\n",
    "                                                target_size=(244,244),\n",
    "                                                batch_size=32,\n",
    "                                                class_mode= \"categorical\")\n",
    "\n",
    "# at once 32 images will be given for training and we have to categorize the images \n",
    "# target size is (244, 244) this is done to ensure that the size of all the images is same when being fed to the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3da6355b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# doing the same for test data\n",
    "test_set = test_datagen.flow_from_directory(\"data_set/test\",\n",
    "                                                target_size=(244,244),\n",
    "                                                batch_size=32,\n",
    "                                                class_mode= \"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a8d599a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "163/163 [==============================] - 1333s 8s/step - loss: 0.2218 - accuracy: 0.9195 - val_loss: 0.2676 - val_accuracy: 0.9038\n",
      "Epoch 2/5\n",
      "163/163 [==============================] - 1349s 8s/step - loss: 0.1067 - accuracy: 0.9594 - val_loss: 0.2933 - val_accuracy: 0.9022\n",
      "Epoch 3/5\n",
      "163/163 [==============================] - 1368s 8s/step - loss: 0.1035 - accuracy: 0.9597 - val_loss: 0.2981 - val_accuracy: 0.9038\n",
      "Epoch 4/5\n",
      "163/163 [==============================] - 1817s 11s/step - loss: 0.0869 - accuracy: 0.9676 - val_loss: 0.2698 - val_accuracy: 0.8958\n",
      "Epoch 5/5\n",
      "163/163 [==============================] - 13999s 86s/step - loss: 0.0930 - accuracy: 0.9664 - val_loss: 0.2250 - val_accuracy: 0.9295\n"
     ]
    }
   ],
   "source": [
    "# now we train our model \n",
    "xray = model.fit(training_set, validation_data= test_set,\n",
    "                          epochs = 5,\n",
    "                          steps_per_epoch = int(len(training_set)),\n",
    "                          validation_steps = int(len(test_set))\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00377505",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[1;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVGG16_pneumonia.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVGG16_pneumonia.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model.save(\"VGG16_skin_cancer.h5\")\n",
    "# loaded_model = load_model(\"VGG16_skin_cancer.h5\")\n",
    "\n",
    "\n",
    "# # alternate way to save :- this one will only save model weights nothing else \n",
    "# # the the above code save everything like optimizer, loss function, the whole \n",
    "# # architechture of the model.\n",
    "\n",
    "# model.save_weights(\"model.h5\")\n",
    "# print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8890539b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "loaded_model = load_model(\"VGG16_skin_cancer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "779d35be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    }
   ],
   "source": [
    "# image has to be converted into numbers --> array to before to be processed\n",
    "\n",
    "img = image.load_img( \"data_set\\\\test\\\\malignant\\\\13.jpg\", target_size = (244,244))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(img, axis = 0)\n",
    "img_data = preprocess_input(x)\n",
    "ans = loaded_model.predict(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "504c2049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb357866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you dont have Pneumonia\n"
     ]
    }
   ],
   "source": [
    "if ans[0][0] == 0:\n",
    "    print(\"you dont have Skin Cancer\")\n",
    "else:\n",
    "    print(\"Sorry, you have Skin Cancer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7c2acb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 206ms/step\n"
     ]
    }
   ],
   "source": [
    "img = image.load_img(  \"data_set\\\\test\\\\benign\\\\154.jpg\", target_size = (244,244))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(img, axis = 0)\n",
    "img_data = preprocess_input(x)\n",
    "ans = loaded_model.predict(img_data)\n",
    "\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1557dc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry, you have Pneumonia\n"
     ]
    }
   ],
   "source": [
    "if ans[0][0] == 0:\n",
    "    print(\"you dont have Skin Cancer\")\n",
    "else:\n",
    "    print(\"Sorry, you have Skin Cancer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac279fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
